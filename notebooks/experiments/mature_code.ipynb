{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_pad = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification of the original loader\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class CalorichEventDataset(Dataset):\n",
    "    def __init__(self, event_with_hit_features_path, hits_path):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.event_with_hit_features_columns = [\n",
    "            'composite_event_id',  # Remember to drop\n",
    "            'ring_radius_cal'      # Added the target, to separate later\n",
    "            # 'total_in_time_hits'\n",
    "        ]\n",
    "\n",
    "        self.event_with_hit_features = (\n",
    "            pl\n",
    "            .read_parquet(event_with_hit_features_path)\n",
    "            .select(self.event_with_hit_features_columns)\n",
    "            .drop_nulls()\n",
    "            .head(100000)\n",
    "            .filter(pl.col('ring_radius_cal').is_not_nan())\n",
    "        )\n",
    "\n",
    "        self.hits_columns = [\n",
    "            'composite_event_id',  # Remember to drop\n",
    "            'x_adjusted', 'y_adjusted'\n",
    "        ]\n",
    "\n",
    "        self.hits = (\n",
    "            pl\n",
    "            .scan_parquet(hits_path)\n",
    "            .select(self.hits_columns)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Size of the dataset\"\"\"\n",
    "        return self.event_with_hit_features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a particular item of the dataset\"\"\"\n",
    "\n",
    "        row = self.event_with_hit_features.row(idx)\n",
    "        composite_event_id = row[0]\n",
    "        hits = (\n",
    "        self.hits\n",
    "        .filter(pl.col(\"composite_event_id\") == composite_event_id)\n",
    "        .drop(\"composite_event_id\")\n",
    "        .collect()\n",
    "        )\n",
    "\n",
    "        # Add 3rd dimension as gaussian noise\n",
    "\n",
    "        noise = np.random.normal(0, 0.05, 30)\n",
    "        noise = np.expand_dims(noise, 1)\n",
    "        \n",
    "\n",
    "        return dict(zip(\n",
    "        self.event_with_hit_features_columns[1:],\n",
    "        torch.tensor(\n",
    "            [n for n in self.event_with_hit_features.row(idx)[1:]])\n",
    "        )) | {\n",
    "            # Hits is now a n*3 tensor array\n",
    "            \"hits\": torch.tensor(np.hstack([hits.sample(n=30, seed=42, with_replacement=True).rows(), noise]))\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://machinelearningmastery.com/training-a-pytorch-model-with-dataloader-and-dataset/\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "class SonarDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    " \n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.X)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        features = self.X[idx]\n",
    "        target = self.y[idx]\n",
    "        return features, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CalorichEventDataset(r'C:\\Users\\merig\\OneDrive\\Documentos\\Projects\\PointNet\\data\\events_with_hit_features_[cut_off_time=0.5].parquet', \n",
    "                               r'C:\\Users\\merig\\OneDrive\\Documentos\\Projects\\PointNet\\data\\hits.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99983"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ring_radius_cal': tensor(173.4102),\n",
       " 'hits': tensor([[-3.4970e+02, -2.2774e+02,  6.8730e-03],\n",
       "         [-3.3170e+02, -2.5892e+02,  5.9248e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  4.4661e-02],\n",
       "         [-3.7670e+02, -2.4333e+02,  3.4971e-02],\n",
       "         [-1.4270e+02, -2.5090e+01,  1.9596e-02],\n",
       "         [-3.4970e+02, -2.2774e+02, -4.4755e-02],\n",
       "         [-3.3170e+02, -2.5892e+02,  1.3603e-02],\n",
       "         [-5.2700e+01, -2.4333e+02, -7.2574e-03],\n",
       "         [-7.9700e+01, -2.9009e+02, -1.1737e-02],\n",
       "         [-3.1370e+02, -4.0680e+01, -1.2001e-05],\n",
       "         [-3.1370e+02, -4.0680e+01,  5.7047e-02],\n",
       "         [-1.6700e+01, -1.8097e+02, -6.1843e-02],\n",
       "         [-1.2470e+02,  6.0900e+00, -6.6166e-03],\n",
       "         [-1.6700e+01, -1.1862e+02, -4.1417e-03],\n",
       "         [-9.7700e+01, -2.9009e+02, -3.2331e-03],\n",
       "         [-3.5870e+02, -1.4980e+02,  4.9204e-02],\n",
       "         [-9.7700e+01, -2.9009e+02, -6.3484e-03],\n",
       "         [-1.6700e+01, -1.8097e+02, -1.0239e-01],\n",
       "         [-1.2470e+02,  6.0900e+00,  5.8562e-02],\n",
       "         [-3.4970e+02, -2.2774e+02, -4.5812e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  8.7512e-03],\n",
       "         [-3.4070e+02, -5.6270e+01,  6.0736e-02],\n",
       "         [-9.7700e+01, -4.0680e+01, -8.1126e-02],\n",
       "         [-6.1700e+01, -4.0680e+01, -8.6891e-03],\n",
       "         [-1.6700e+01, -1.1862e+02,  1.8034e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -3.2505e-02],\n",
       "         [-9.7700e+01, -4.0680e+01,  1.6082e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  6.7877e-02],\n",
       "         [-1.2470e+02,  6.0900e+00, -4.3526e-02],\n",
       "         [-3.3170e+02, -2.5892e+02, -6.6564e-03]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.__getitem__(0)['hits'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' #Use Cuda GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PadCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(vec, pad, dim):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        vec - tensor to pad\n",
    "        pad - the size to pad to\n",
    "        dim - dimension to pad\n",
    "\n",
    "    return:\n",
    "        a new tensor padded to 'pad' in dimension 'dim'\n",
    "    \"\"\"\n",
    "    pad_size = list(vec.shape)\n",
    "    pad_size[dim] = pad - vec.size(dim)\n",
    "    return torch.cat([vec, torch.zeros(*pad_size)], dim=dim)\n",
    "\n",
    "\n",
    "class PadCollate:\n",
    "    \"\"\"\n",
    "    a variant of callate_fn that pads according to the longest sequence in\n",
    "    a batch of sequences\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim=0):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            dim - the dimension to be padded (dimension of time in sequences)\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "\n",
    "    def pad_collate(self, batch):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            batch - list of (tensor, label)\n",
    "\n",
    "        reutrn:\n",
    "            xs - a tensor of all examples in 'batch' after padding\n",
    "            ys - a LongTensor of all labels in batch\n",
    "        \"\"\"\n",
    "        # find longest sequence\n",
    "        max_len = max(map(lambda x: x[0].shape[self.dim], batch))\n",
    "        # pad according to max_len\n",
    "        batch = map(lambda x, y:\n",
    "                    (pad_tensor(x, pad=max_len, dim=self.dim), y), batch)\n",
    "        # stack all\n",
    "        xs = torch.stack(map(lambda x: x[0], batch), dim=0)\n",
    "        ys = torch.LongTensor(map(lambda x: x[1], batch))\n",
    "        return xs, ys\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        return self.pad_collate(batch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 10000\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "indices = list(range(dataset.__len__()))\n",
    "split = int(np.floor(validation_split * dataset.__len__()))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PointNet implementation for the RICH AI project.\n",
    "\n",
    "Adapted from:\n",
    "https://github.com/charlesq34/pointnet (Author implementation)\n",
    "http://stanford.edu/~rqi/pointnet/ (Original paper)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    \"\"\"TNet Implementation in PyTorch.\n",
    "    k x k transformation matrix predicted by T-Net to coordinates of input points.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=64):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.iden = Variable(\n",
    "            torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))\n",
    "        ).view(1, -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = nn.MaxPool1d(x.size(-1))(x)\n",
    "        x = nn.Flatten(1)(x)\n",
    "        x = self.relu(self.bn4(self.fc1(x)))\n",
    "        x = self.relu(self.bn5(self.fc2(x)))\n",
    "\n",
    "        # initialize as identity\n",
    "        iden = torch.eye(self.k, requires_grad=True).repeat(batchsize, 1, 1)\n",
    "        iden = iden.to(device)\n",
    "        x = self.fc3(x).view(-1, self.k, self.k) + iden\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "    \"\"\"Input and Feature Transform module.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = STNkd(k=3)\n",
    "        self.feature_transform = STNkd(k=64)\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # batch matrix multiplication\n",
    "        # input transform\n",
    "        x = torch.bmm(torch.transpose(x, 1, 2), self.input_transform(x)).transpose(1, 2)\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Feature transform\n",
    "        x = torch.bmm(torch.transpose(x, 1, 2), self.feature_transform(x)).transpose(\n",
    "            1, 2\n",
    "        )\n",
    "\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = nn.MaxPool1d(x.size(-1))(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PointNetFc(nn.Module):\n",
    "    \"\"\"PointNet fully connected network.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of classes in the classification network.\n",
    "    momentum : bool\n",
    "        If True, include momentum as feature.\n",
    "    radius : bool\n",
    "        If True, include radius as feature.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(x, momentum, radius)\n",
    "        Feed forward nn layer with input x, momentum and radius.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        momentum=False,\n",
    "        radius=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.momentum = momentum\n",
    "        self.radius = radius\n",
    "\n",
    "        self.feat = Transform()\n",
    "\n",
    "        # include radius and momentum\n",
    "        if self.momentum and self.radius:\n",
    "            self.fc1 = nn.Linear(1024 + 2, 512)\n",
    "        elif self.momentum or self.radius:\n",
    "            self.fc1 = nn.Linear(1024 + 1, 512)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(1024, 512)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, momentum=None, radius=None):\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        x = self.feat(x)\n",
    "\n",
    "        # add momentum dimension if desired\n",
    "        if self.momentum and momentum is not None:\n",
    "            x = torch.hstack([x, momentum.unsqueeze(1)])\n",
    "\n",
    "        # add radius dimension if desired\n",
    "        if self.radius and radius is not None:\n",
    "            x = torch.hstack([x, radius.unsqueeze(1)])\n",
    "\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jack's Pointnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "\n",
    "        self.conv_network = nn.Sequential(\n",
    "            nn.Conv1d(k, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_network = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, k * k)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv_network(x)\n",
    "        x = nn.AdaptiveMaxPool1d(1)(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc_network(x)\n",
    "\n",
    "        identity_matrix = torch.eye(self.k, device=x.device).view(1, self.k * self.k).repeat(batch_size, 1)\n",
    "        matrix = x + identity_matrix\n",
    "        return matrix.view(batch_size, self.k, self.k)\n",
    "\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=1024):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.input_transform = TNet(k=input_dim)\n",
    "        self.feature_transform = TNet(k=64)\n",
    "\n",
    "        self.input_network = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.feature_network = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, output_dim, 1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv3 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv4 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv5 = nn.Conv1d(128, output_dim, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.bn5 = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Transpose input data to match expected dimensions\n",
    "        x = x.transpose(2, 1)\n",
    "\n",
    "        input_transform = self.input_transform(x)\n",
    "        x = torch.bmm(x.transpose(1, 2), input_transform).transpose(1, 2)\n",
    "\n",
    "        x = self.input_network(x)\n",
    "\n",
    "        feature_transform = self.feature_transform(x)\n",
    "        x = torch.bmm(x.transpose(1, 2), feature_transform).transpose(1, 2)\n",
    "\n",
    "        x = self.feature_network(x)\n",
    "        x = nn.AdaptiveMaxPool1d(1)(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointNetRegression(nn.Module):\n",
    "    def __init__(self, num_features, num_output):\n",
    "        super(PointNetRegression, self).__init__()\n",
    "        \n",
    "        # Input transformation network\n",
    "        self.input_transform = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 64, kernel_size=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, kernel_size=1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Feature transformation network\n",
    "        self.feature_transform = nn.Sequential(\n",
    "            nn.Conv1d(1024, 512, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 256, kernel_size=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers for regression\n",
    "        self.fc_regression = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Input transformation network\n",
    "        x = self.input_transform(x)\n",
    "        \n",
    "        # Global feature extraction\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        # Feature transformation network\n",
    "        x = self.feature_transform(x)\n",
    "        \n",
    "        # Global feature vector\n",
    "        x = torch.max(x, 2, keepdim=False)[0]\n",
    "        \n",
    "        # Fully connected layers for regression\n",
    "        x = self.fc_regression(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system?True\n",
      "CUDA version: 11.8\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system?{torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "\t\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "model = PointNetRegression(30, 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "[INFO] epoch: 1...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     14\u001b[0m     X \u001b[39m=\u001b[39m d[\u001b[39m'\u001b[39m\u001b[39mhits\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device) \u001b[39m# Check why the change into a different datatype and why send it to device\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     y \u001b[39m=\u001b[39m d[\u001b[39m'\u001b[39m\u001b[39mring_radius_cal\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device) \u001b[39m# Remember, I removed the .long() before .to(device) to get the decimal points (does not make sense)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[46], line 50\u001b[0m, in \u001b[0;36mCalorichEventDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     44\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_with_hit_features\u001b[39m.\u001b[39mrow(idx)\n\u001b[0;32m     45\u001b[0m composite_event_id \u001b[39m=\u001b[39m row[\u001b[39m0\u001b[39m]\n\u001b[0;32m     46\u001b[0m hits \u001b[39m=\u001b[39m (\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhits\n\u001b[0;32m     48\u001b[0m \u001b[39m.\u001b[39;49mfilter(pl\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mcomposite_event_id\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m==\u001b[39;49m composite_event_id)\n\u001b[0;32m     49\u001b[0m \u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mcomposite_event_id\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m---> 50\u001b[0m \u001b[39m.\u001b[39;49mcollect()\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     53\u001b[0m \u001b[39m# Add 3rd dimension as gaussian noise\u001b[39;00m\n\u001b[0;32m     55\u001b[0m noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m30\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\polars\\lazyframe\\frame.py:1501\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, common_subplan_elimination, streaming)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     common_subplan_elimination \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m ldf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf\u001b[39m.\u001b[39moptimization_toggle(\n\u001b[0;32m   1493\u001b[0m     type_coercion,\n\u001b[0;32m   1494\u001b[0m     predicate_pushdown,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     streaming,\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_df(ldf\u001b[39m.\u001b[39;49mcollect())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "model.to(device)\n",
    "trainTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
    "training_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(\"[INFO] epoch: {}...\".format(epoch + 1))\n",
    "    epoch_start = time.time()\n",
    "    train_losses, train_accs = [], []\n",
    "    samples = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, d in enumerate(train_loader):\n",
    "        X = d['hits'].float().to(device) # Check why the change into a different datatype and why send it to device\n",
    "        y = d['ring_radius_cal'].to(device) # Remember, I removed the .long() before .to(device) to get the decimal points (does not make sense)\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, y) # erased long() from y.long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item() * y.size(0)) # Changed to append\n",
    "        train_accs.append(torch.sub(predictions[0], y).mean().item()) # Added the () in sum()\n",
    "        samples += y.size(0)\n",
    "\n",
    "        print(f\"Epoch: {epoch + 1} step: {i} with loss: {loss.item()} and accuracy: {train_accs[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 2-dimensional tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Access the first row\n",
    "first_row = tensor[0]\n",
    "\n",
    "# Print the first row\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-180.19786071777344"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(predictions[0], y).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([182.7963, 184.0354, 174.6605, 180.2903, 178.0977, 187.0254, 183.7213,\n",
       "        185.5659, 179.0477, 185.0293, 182.6094, 186.9826, 188.4289, 170.6696,\n",
       "        157.1055, 181.7249])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2891],\n",
       "        [0.5397],\n",
       "        [0.6509],\n",
       "        [0.5128],\n",
       "        [0.7593],\n",
       "        [0.4565],\n",
       "        [0.3884],\n",
       "        [0.3801],\n",
       "        [0.3278],\n",
       "        [0.3868],\n",
       "        [0.3556],\n",
       "        [0.4102],\n",
       "        [0.4384],\n",
       "        [0.5259],\n",
       "        [0.3993],\n",
       "        [0.4437]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0931], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0931],\n",
       "        [ 0.0632],\n",
       "        [-0.0740],\n",
       "        [ 0.1198],\n",
       "        [ 0.0014],\n",
       "        [ 0.0017],\n",
       "        [ 0.1453],\n",
       "        [ 0.0166],\n",
       "        [ 0.1948],\n",
       "        [ 0.0509],\n",
       "        [ 0.0216],\n",
       "        [-0.0144],\n",
       "        [ 0.1741],\n",
       "        [ 0.0872],\n",
       "        [ 0.1278],\n",
       "        [ 0.1137]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([184.9212, 188.0985, 184.8985, 177.8908, 188.6279, 182.0576, 187.7453,\n",
       "        183.8123, 182.5473, 187.1304, 157.1055, 179.3441, 177.7729, 170.6696,\n",
       "        167.0399, 183.4079])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x151137580>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of d: 2\n",
      "value of i: 0\n",
      "size of X: 16\n",
      "size of y: 16\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(validation_loader, 0):\n",
    "    y = d['ring_radius_cal']\n",
    "    X = d['hits']\n",
    "\n",
    "    print(f\"size of d: {len(d.items())}\" )\n",
    "    print(f\"value of i: {i}\" )\n",
    "    print(f\"size of X: {len(X)}\")\n",
    "    print(f\"size of y: {len(y)}\")\n",
    "\n",
    "\n",
    "    # print(X.size())\n",
    "    # print(y.size())\n",
    "    # print(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of d: 2\n",
      "value of i: 0\n",
      "size of X: 16\n",
      "size of y: 16\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(train_loader, 0):\n",
    "    y = d['ring_radius_cal']\n",
    "    X = d['hits']\n",
    "\n",
    "    print(f\"size of d: {len(d.items())}\" )\n",
    "    print(f\"value of i: {i}\" )\n",
    "    print(f\"size of X: {len(X)}\")\n",
    "    print(f\"size of y: {len(y)}\")\n",
    "\n",
    "\n",
    "    # print(X.size())\n",
    "    # print(y.size())\n",
    "    # print(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ring_radius_cal': tensor(173.4102),\n",
       " 'hits': tensor([[-3.4970e+02, -2.2774e+02, -4.6963e-02],\n",
       "         [-3.3170e+02, -2.5892e+02,  9.1718e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -6.1191e-02],\n",
       "         [-3.7670e+02, -2.4333e+02, -1.5209e-02],\n",
       "         [-1.4270e+02, -2.5090e+01,  5.6494e-03],\n",
       "         [-3.4970e+02, -2.2774e+02,  3.5191e-02],\n",
       "         [-3.3170e+02, -2.5892e+02,  8.9147e-02],\n",
       "         [-5.2700e+01, -2.4333e+02, -5.1090e-02],\n",
       "         [-7.9700e+01, -2.9009e+02, -3.3477e-03],\n",
       "         [-3.1370e+02, -4.0680e+01,  6.4508e-03],\n",
       "         [-3.1370e+02, -4.0680e+01, -7.5159e-02],\n",
       "         [-1.6700e+01, -1.8097e+02, -3.8311e-02],\n",
       "         [-1.2470e+02,  6.0900e+00,  3.8668e-03],\n",
       "         [-1.6700e+01, -1.1862e+02, -7.5247e-02],\n",
       "         [-9.7700e+01, -2.9009e+02, -1.8152e-03],\n",
       "         [-3.5870e+02, -1.4980e+02,  3.3626e-02],\n",
       "         [-9.7700e+01, -2.9009e+02,  2.6931e-03],\n",
       "         [-1.6700e+01, -1.8097e+02, -3.2215e-02],\n",
       "         [-1.2470e+02,  6.0900e+00, -1.1841e-02],\n",
       "         [-3.4970e+02, -2.2774e+02, -7.3504e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  3.9915e-02],\n",
       "         [-3.4070e+02, -5.6270e+01, -3.1827e-02],\n",
       "         [-9.7700e+01, -4.0680e+01, -4.4228e-02],\n",
       "         [-6.1700e+01, -4.0680e+01,  6.7874e-02],\n",
       "         [-1.6700e+01, -1.1862e+02, -5.4752e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -7.4192e-03],\n",
       "         [-9.7700e+01, -4.0680e+01,  1.3756e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -4.1790e-02],\n",
       "         [-1.2470e+02,  6.0900e+00, -3.0841e-04],\n",
       "         [-3.3170e+02, -2.5892e+02,  7.5793e-02]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 0.05, 30)\n",
    "noise = np.expand_dims(noise, 1)\n",
    "noise.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "591",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
