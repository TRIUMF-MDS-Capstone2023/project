{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import time\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_pad = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification of the original loader\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class CalorichEventDataset(Dataset):\n",
    "    def __init__(self, event_with_hit_features_path, hits_path):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.event_with_hit_features_columns = [\n",
    "            'composite_event_id',  # Remember to drop\n",
    "            'ring_radius_cal'      # Added the target, to separate later\n",
    "            # 'total_in_time_hits'\n",
    "        ]\n",
    "\n",
    "        self.event_with_hit_features = (\n",
    "            pl\n",
    "            .read_parquet(event_with_hit_features_path)\n",
    "            .select(self.event_with_hit_features_columns)\n",
    "            .drop_nulls()\n",
    "            .head(1000)\n",
    "            .filter(pl.col('ring_radius_cal').is_not_nan())\n",
    "        )\n",
    "\n",
    "        self.hits_columns = [\n",
    "            'composite_event_id',  # Remember to drop\n",
    "            'x_adjusted', 'y_adjusted'\n",
    "        ]\n",
    "\n",
    "        self.hits = (\n",
    "            pl\n",
    "            .scan_parquet(hits_path)\n",
    "            .select(self.hits_columns)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Size of the dataset\"\"\"\n",
    "        return self.event_with_hit_features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a particular item of the dataset\"\"\"\n",
    "\n",
    "        row = self.event_with_hit_features.row(idx)\n",
    "        composite_event_id = row[0]\n",
    "        hits = (\n",
    "        self.hits\n",
    "        .filter(pl.col(\"composite_event_id\") == composite_event_id)\n",
    "        .drop(\"composite_event_id\")\n",
    "        .collect()\n",
    "        )\n",
    "\n",
    "        # Add 3rd dimension as gaussian noise\n",
    "\n",
    "        noise = np.random.normal(0, 0.05, 30)\n",
    "        noise = np.expand_dims(noise, 1)\n",
    "        \n",
    "\n",
    "        return dict(zip(\n",
    "        self.event_with_hit_features_columns[1:],\n",
    "        torch.tensor(\n",
    "            [n for n in self.event_with_hit_features.row(idx)[1:]])\n",
    "        )) | {\n",
    "            # Hits is now a n*3 tensor array\n",
    "            \"hits\": torch.tensor(np.hstack([hits.sample(n=size_pad, seed=42, with_replacement=True).rows(), noise])).to(device)\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CalorichEventDataset(r'C:\\Users\\merig\\OneDrive\\Documentos\\Projects\\PointNet\\data\\events_with_hit_features_[cut_off_time=0.5].parquet', \n",
    "                               r'C:\\Users\\merig\\OneDrive\\Documentos\\Projects\\PointNet\\data\\hits.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ring_radius_cal': tensor(173.4102),\n",
       " 'hits': tensor([[-3.4970e+02, -2.2774e+02, -2.2288e-02],\n",
       "         [-3.3170e+02, -2.5892e+02, -3.9044e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  2.4509e-03],\n",
       "         [-3.7670e+02, -2.4333e+02,  4.0280e-02],\n",
       "         [-1.4270e+02, -2.5090e+01, -3.9893e-02],\n",
       "         [-3.4970e+02, -2.2774e+02,  2.3448e-02],\n",
       "         [-3.3170e+02, -2.5892e+02, -3.1577e-02],\n",
       "         [-5.2700e+01, -2.4333e+02,  2.7645e-02],\n",
       "         [-7.9700e+01, -2.9009e+02, -7.0915e-02],\n",
       "         [-3.1370e+02, -4.0680e+01,  1.6554e-02],\n",
       "         [-3.1370e+02, -4.0680e+01,  3.8165e-02],\n",
       "         [-1.6700e+01, -1.8097e+02, -1.8169e-02],\n",
       "         [-1.2470e+02,  6.0900e+00,  4.7826e-02],\n",
       "         [-1.6700e+01, -1.1862e+02, -1.8540e-02],\n",
       "         [-9.7700e+01, -2.9009e+02, -6.3188e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  2.5080e-02],\n",
       "         [-9.7700e+01, -2.9009e+02,  2.2734e-02],\n",
       "         [-1.6700e+01, -1.8097e+02,  6.1609e-03],\n",
       "         [-1.2470e+02,  6.0900e+00,  4.9652e-02],\n",
       "         [-3.4970e+02, -2.2774e+02, -4.5860e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  3.7312e-03],\n",
       "         [-3.4070e+02, -5.6270e+01, -8.6768e-02],\n",
       "         [-9.7700e+01, -4.0680e+01, -7.9005e-02],\n",
       "         [-6.1700e+01, -4.0680e+01,  4.8997e-02],\n",
       "         [-1.6700e+01, -1.1862e+02, -7.3834e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -3.5647e-02],\n",
       "         [-9.7700e+01, -4.0680e+01, -3.4240e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  1.3546e-01],\n",
       "         [-1.2470e+02,  6.0900e+00,  1.3465e-02],\n",
       "         [-3.3170e+02, -2.5892e+02, -1.4238e-02]], device='cuda:0',\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.__getitem__(0)['hits'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Tensors to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_name = 'this_test'\n",
    "torch.save(dataset.__getitem__(0), os.path.join(locale, f'{test_name}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale = r'C:\\Users\\merig\\Documents\\Projects\\PointNet\\data\\tensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(head):\n",
    "    torch.save(dataset.__getitem__(i), os.path.join(locale, f'{i}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(173.4102)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(os.path.join(locale, f'{0}.pt'))['ring_radius_cal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = torch.load(os.path.join(locale, f'{0}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict.update(torch.load(os.path.join(locale, f'{1}.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ring_radius_cal': tensor(174.6605),\n",
       " 'hits': tensor([[-3.4970e+02, -2.2774e+02, -8.5467e-02],\n",
       "         [-3.9470e+02, -2.1215e+02, -8.6957e-02],\n",
       "         [-3.9470e+02, -2.1215e+02, -3.7858e-03],\n",
       "         [-3.7670e+02, -2.4333e+02,  1.1493e-02],\n",
       "         [-3.1370e+02,  8.4030e+01, -2.4771e-02],\n",
       "         [-3.7670e+02, -2.1215e+02,  4.8322e-02],\n",
       "         [-2.7770e+02,  1.1521e+02,  1.7689e-03],\n",
       "         [-1.2880e+02, -1.6010e+02, -2.2489e-03],\n",
       "         [-2.0570e+02, -1.9656e+02, -4.6417e-02],\n",
       "         [-4.8470e+02, -5.6270e+01, -7.3546e-03],\n",
       "         [-4.8470e+02, -5.6270e+01, -1.3740e-01],\n",
       "         [-1.4270e+02, -1.1862e+02, -4.8820e-03],\n",
       "         [-3.4970e+02,  1.1521e+02,  1.0032e-02],\n",
       "         [-2.2370e+02, -1.9656e+02, -4.9081e-02],\n",
       "         [-2.3270e+02, -2.4333e+02, -3.8641e-02],\n",
       "         [-3.1370e+02,  8.4030e+01, -3.0103e-02],\n",
       "         [-1.6070e+02, -1.1862e+02,  1.2037e-01],\n",
       "         [-1.4270e+02, -1.1862e+02, -3.5665e-02],\n",
       "         [-3.4970e+02,  1.1521e+02,  1.4165e-02],\n",
       "         [-3.4970e+02, -2.2774e+02, -3.2295e-02],\n",
       "         [-3.9470e+02, -2.1215e+02, -1.0799e-02],\n",
       "         [-4.2170e+02, -2.2774e+02, -6.7797e-03],\n",
       "         [-1.6480e+02, -1.6010e+02, -2.2931e-02],\n",
       "         [-3.4970e+02,  1.1521e+02, -3.7066e-02],\n",
       "         [-2.2370e+02, -1.9656e+02,  6.0816e-03],\n",
       "         [-3.5870e+02,  9.9620e+01, -3.8064e-02],\n",
       "         [-4.8470e+02, -5.6270e+01,  1.1658e-02],\n",
       "         [-3.9470e+02, -2.1215e+02, -1.9875e-02],\n",
       "         [-2.7770e+02,  1.1521e+02,  6.2063e-02],\n",
       "         [-2.7770e+02,  1.1521e+02,  2.9483e-02]], device='cuda:0',\n",
       "        dtype=torch.float64)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(os.path.join(locale, f'{0}.pt'))['hits']\n",
    "b = torch.load(os.path.join(locale, f'{1}.pt'))['hits']\n",
    "test_cat = torch.cat((a, b), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4970e+02, -2.2774e+02, -2.4646e-02],\n",
       "        [-3.3170e+02, -2.5892e+02, -1.8230e-02],\n",
       "        [-3.5870e+02, -1.4980e+02, -8.9511e-03],\n",
       "        [-3.7670e+02, -2.4333e+02,  3.1408e-02],\n",
       "        [-1.4270e+02, -2.5090e+01, -2.2773e-02],\n",
       "        [-3.4970e+02, -2.2774e+02, -5.5075e-02],\n",
       "        [-3.3170e+02, -2.5892e+02, -3.1802e-02],\n",
       "        [-5.2700e+01, -2.4333e+02,  6.7771e-02],\n",
       "        [-7.9700e+01, -2.9009e+02, -4.9130e-02],\n",
       "        [-3.1370e+02, -4.0680e+01,  8.1258e-02],\n",
       "        [-3.1370e+02, -4.0680e+01,  4.9169e-03],\n",
       "        [-1.6700e+01, -1.8097e+02, -4.0932e-02],\n",
       "        [-1.2470e+02,  6.0900e+00,  1.9684e-02],\n",
       "        [-1.6700e+01, -1.1862e+02, -6.5588e-03],\n",
       "        [-9.7700e+01, -2.9009e+02, -4.4177e-02],\n",
       "        [-3.5870e+02, -1.4980e+02, -5.3689e-02],\n",
       "        [-9.7700e+01, -2.9009e+02,  5.4376e-02],\n",
       "        [-1.6700e+01, -1.8097e+02,  4.9624e-02],\n",
       "        [-1.2470e+02,  6.0900e+00, -5.5119e-02],\n",
       "        [-3.4970e+02, -2.2774e+02,  1.0583e-01],\n",
       "        [-3.5870e+02, -1.4980e+02,  5.5456e-02],\n",
       "        [-3.4070e+02, -5.6270e+01, -6.2426e-02],\n",
       "        [-9.7700e+01, -4.0680e+01, -6.0446e-05],\n",
       "        [-6.1700e+01, -4.0680e+01, -2.0725e-02],\n",
       "        [-1.6700e+01, -1.1862e+02, -1.3992e-02],\n",
       "        [-3.5870e+02, -1.4980e+02, -7.1496e-02],\n",
       "        [-9.7700e+01, -4.0680e+01,  1.0516e-02],\n",
       "        [-3.5870e+02, -1.4980e+02,  7.8954e-02],\n",
       "        [-1.2470e+02,  6.0900e+00,  1.2018e-03],\n",
       "        [-3.3170e+02, -2.5892e+02, -1.0766e-01],\n",
       "        [-3.4970e+02, -2.2774e+02, -8.5467e-02],\n",
       "        [-3.9470e+02, -2.1215e+02, -8.6957e-02],\n",
       "        [-3.9470e+02, -2.1215e+02, -3.7858e-03],\n",
       "        [-3.7670e+02, -2.4333e+02,  1.1493e-02],\n",
       "        [-3.1370e+02,  8.4030e+01, -2.4771e-02],\n",
       "        [-3.7670e+02, -2.1215e+02,  4.8322e-02],\n",
       "        [-2.7770e+02,  1.1521e+02,  1.7689e-03],\n",
       "        [-1.2880e+02, -1.6010e+02, -2.2489e-03],\n",
       "        [-2.0570e+02, -1.9656e+02, -4.6417e-02],\n",
       "        [-4.8470e+02, -5.6270e+01, -7.3546e-03],\n",
       "        [-4.8470e+02, -5.6270e+01, -1.3740e-01],\n",
       "        [-1.4270e+02, -1.1862e+02, -4.8820e-03],\n",
       "        [-3.4970e+02,  1.1521e+02,  1.0032e-02],\n",
       "        [-2.2370e+02, -1.9656e+02, -4.9081e-02],\n",
       "        [-2.3270e+02, -2.4333e+02, -3.8641e-02],\n",
       "        [-3.1370e+02,  8.4030e+01, -3.0103e-02],\n",
       "        [-1.6070e+02, -1.1862e+02,  1.2037e-01],\n",
       "        [-1.4270e+02, -1.1862e+02, -3.5665e-02],\n",
       "        [-3.4970e+02,  1.1521e+02,  1.4165e-02],\n",
       "        [-3.4970e+02, -2.2774e+02, -3.2295e-02],\n",
       "        [-3.9470e+02, -2.1215e+02, -1.0799e-02],\n",
       "        [-4.2170e+02, -2.2774e+02, -6.7797e-03],\n",
       "        [-1.6480e+02, -1.6010e+02, -2.2931e-02],\n",
       "        [-3.4970e+02,  1.1521e+02, -3.7066e-02],\n",
       "        [-2.2370e+02, -1.9656e+02,  6.0816e-03],\n",
       "        [-3.5870e+02,  9.9620e+01, -3.8064e-02],\n",
       "        [-4.8470e+02, -5.6270e+01,  1.1658e-02],\n",
       "        [-3.9470e+02, -2.1215e+02, -1.9875e-02],\n",
       "        [-2.7770e+02,  1.1521e+02,  6.2063e-02],\n",
       "        [-2.7770e+02,  1.1521e+02,  2.9483e-02]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disk Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path \n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        tensor = torch.load(os.path.join(self.path, f'{i}.pt'))\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EmbedDataset(locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmbedDataset' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset\u001b[39m.\u001b[39;49m\u001b[39m__len__\u001b[39;49m()\n",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m, in \u001b[0;36mEmbedDataset.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EmbedDataset' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PadCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(vec, pad, dim):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        vec - tensor to pad\n",
    "        pad - the size to pad to\n",
    "        dim - dimension to pad\n",
    "\n",
    "    return:\n",
    "        a new tensor padded to 'pad' in dimension 'dim'\n",
    "    \"\"\"\n",
    "    pad_size = list(vec.shape)\n",
    "    pad_size[dim] = pad - vec.size(dim)\n",
    "    return torch.cat([vec, torch.zeros(*pad_size)], dim=dim)\n",
    "\n",
    "\n",
    "class PadCollate:\n",
    "    \"\"\"\n",
    "    a variant of callate_fn that pads according to the longest sequence in\n",
    "    a batch of sequences\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim=0):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            dim - the dimension to be padded (dimension of time in sequences)\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "\n",
    "    def pad_collate(self, batch):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            batch - list of (tensor, label)\n",
    "\n",
    "        reutrn:\n",
    "            xs - a tensor of all examples in 'batch' after padding\n",
    "            ys - a LongTensor of all labels in batch\n",
    "        \"\"\"\n",
    "        # find longest sequence\n",
    "        max_len = max(map(lambda x: x[0].shape[self.dim], batch))\n",
    "        # pad according to max_len\n",
    "        batch = map(lambda x, y:\n",
    "                    (pad_tensor(x, pad=max_len, dim=self.dim), y), batch)\n",
    "        # stack all\n",
    "        xs = torch.stack(map(lambda x: x[0], batch), dim=0)\n",
    "        ys = torch.LongTensor(map(lambda x: x[1], batch))\n",
    "        return xs, ys\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        return self.pad_collate(batch)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 10\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "num_workers = 0\n",
    "pin_memory = False\n",
    "\n",
    "\n",
    "indices = list(range(dataset.__len__()))\n",
    "split = int(np.floor(validation_split * dataset.__len__()))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler, num_workers = num_workers, pin_memory = pin_memory)\n",
    "validation_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler, num_workers = num_workers, pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x242764f2020>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PointNet implementation for the RICH AI project.\n",
    "\n",
    "Adapted from:\n",
    "https://github.com/charlesq34/pointnet (Author implementation)\n",
    "http://stanford.edu/~rqi/pointnet/ (Original paper)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    \"\"\"TNet Implementation in PyTorch.\n",
    "    k x k transformation matrix predicted by T-Net to coordinates of input points.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=64):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.iden = Variable(\n",
    "            torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))\n",
    "        ).view(1, -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = nn.MaxPool1d(x.size(-1))(x)\n",
    "        x = nn.Flatten(1)(x)\n",
    "        x = self.relu(self.bn4(self.fc1(x)))\n",
    "        x = self.relu(self.bn5(self.fc2(x)))\n",
    "\n",
    "        # initialize as identity\n",
    "        iden = torch.eye(self.k, requires_grad=True).repeat(batchsize, 1, 1)\n",
    "        iden = iden.to(device)\n",
    "        x = self.fc3(x).view(-1, self.k, self.k) + iden\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "    \"\"\"Input and Feature Transform module.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = STNkd(k=3)\n",
    "        self.feature_transform = STNkd(k=64)\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # batch matrix multiplication\n",
    "        # input transform\n",
    "        x = torch.bmm(torch.transpose(x, 1, 2), self.input_transform(x)).transpose(1, 2)\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Feature transform\n",
    "        x = torch.bmm(torch.transpose(x, 1, 2), self.feature_transform(x)).transpose(\n",
    "            1, 2\n",
    "        )\n",
    "\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = nn.MaxPool1d(x.size(-1))(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PointNetFc(nn.Module):\n",
    "    \"\"\"PointNet fully connected network.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_classes : int\n",
    "        Number of classes in the classification network.\n",
    "    momentum : bool\n",
    "        If True, include momentum as feature.\n",
    "    radius : bool\n",
    "        If True, include radius as feature.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(x, momentum, radius)\n",
    "        Feed forward nn layer with input x, momentum and radius.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes,\n",
    "        momentum=False,\n",
    "        radius=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.momentum = momentum\n",
    "        self.radius = radius\n",
    "\n",
    "        self.feat = Transform()\n",
    "\n",
    "        # include radius and momentum\n",
    "        if self.momentum and self.radius:\n",
    "            self.fc1 = nn.Linear(1024 + 2, 512)\n",
    "        elif self.momentum or self.radius:\n",
    "            self.fc1 = nn.Linear(1024 + 1, 512)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(1024, 512)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, momentum=None, radius=None):\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        x = self.feat(x)\n",
    "\n",
    "        # add momentum dimension if desired\n",
    "        if self.momentum and momentum is not None:\n",
    "            x = torch.hstack([x, momentum.unsqueeze(1)])\n",
    "\n",
    "        # add radius dimension if desired\n",
    "        if self.radius and radius is not None:\n",
    "            x = torch.hstack([x, radius.unsqueeze(1)])\n",
    "\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.relu(self.bn2(self.dropout(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jack's Pointnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "\n",
    "        self.conv_network = nn.Sequential(\n",
    "            nn.Conv1d(k, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_network = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, k * k)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv_network(x)\n",
    "        x = nn.AdaptiveMaxPool1d(1)(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc_network(x)\n",
    "\n",
    "        identity_matrix = torch.eye(self.k, device=x.device).view(1, self.k * self.k).repeat(batch_size, 1)\n",
    "        matrix = x + identity_matrix\n",
    "        return matrix.view(batch_size, self.k, self.k)\n",
    "\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=1024):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.input_transform = TNet(k=input_dim)\n",
    "        self.feature_transform = TNet(k=64)\n",
    "\n",
    "        self.input_network = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.feature_network = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, output_dim, 1),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv3 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv4 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv5 = nn.Conv1d(128, output_dim, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.bn5 = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Transpose input data to match expected dimensions\n",
    "        x = x.transpose(2, 1)\n",
    "\n",
    "        input_transform = self.input_transform(x)\n",
    "        x = torch.bmm(x.transpose(1, 2), input_transform).transpose(1, 2)\n",
    "\n",
    "        x = self.input_network(x)\n",
    "\n",
    "        feature_transform = self.feature_transform(x)\n",
    "        x = torch.bmm(x.transpose(1, 2), feature_transform).transpose(1, 2)\n",
    "\n",
    "        x = self.feature_network(x)\n",
    "        x = nn.AdaptiveMaxPool1d(1)(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PointNet for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointNetRegression(nn.Module):\n",
    "    def __init__(self, num_features, num_output):\n",
    "        super(PointNetRegression, self).__init__()\n",
    "        \n",
    "        # Input transformation network\n",
    "        self.input_transform = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 64, kernel_size=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, kernel_size=1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Feature transformation network\n",
    "        self.feature_transform = nn.Sequential(\n",
    "            nn.Conv1d(1024, 512, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(512, 256, kernel_size=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers for regression\n",
    "        self.fc_regression = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Input transformation network\n",
    "        x = self.input_transform(x)\n",
    "        \n",
    "        # Global feature extraction\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        # Feature transformation network\n",
    "        x = self.feature_transform(x)\n",
    "        \n",
    "        # Global feature vector\n",
    "        x = torch.max(x, 2, keepdim=False)[0]\n",
    "        \n",
    "        # Fully connected layers for regression\n",
    "        x = self.fc_regression(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.8\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "\t\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_trainer(model, criterion, optimizer, trainloader, validloader, epochs = 5, patience = 5, verbose = True):\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    start_time = 0\n",
    "    end_time = 0\n",
    "    print(device)\n",
    "    start_time = time.time()\n",
    "    model.to(device)\n",
    "    end_time = time.time()\n",
    "    print(f'Model loading took {end_time - start_time:.3f} seconds')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_batch_loss = 0\n",
    "        valid_batch_loss = 0\n",
    "\n",
    "        # Start the trainer\n",
    "\n",
    "        for i, d in enumerate(trainloader):\n",
    "            print(f'Iteration {i + 1}')\n",
    "            start_time = time.time()\n",
    "            X = d['hits'].float() # float32\n",
    "            y = d['ring_radius_cal'].float().to(device) # float32\n",
    "            y = y.unsqueeze(1)\n",
    "            end_time = time.time()\n",
    "            # print(f'Data loading time: {end_time - start_time:.3f}')\n",
    "\n",
    "            # Model is used\n",
    "            start_time = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X)\n",
    "            end_time = time.time()\n",
    "            # print(f'The model took {end_time - start_time:.3f} seconds to run with cuda = {X.is_cuda} and {X.type()} training dataset and cuda = {y.is_cuda} and {y.type()} ground truth dataset')\n",
    "\n",
    "            # Loss\n",
    "        \n",
    "            start_time = time.time()\n",
    "            loss = criterion(predictions, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            end_time = time.time()\n",
    "            # print(f'The loss process took {end_time - start_time:.3f} seconds')\n",
    "            train_batch_loss += loss.item()\n",
    "\n",
    "        train_loss.append(loss.item() / len(train_loader))\n",
    "\n",
    "        # Validation Loop\n",
    "\n",
    "        with torch.no_grad(): # Stops graph computations\n",
    "\n",
    "            for X_valid, y_valid in enumerate(validloader):\n",
    "                start_time = time.time()\n",
    "                X_valid = d['hits'].float() # float32\n",
    "                y_valid = d['ring_radius_cal'].float().to(device) # float32\n",
    "                y_valid = y_valid.unsqueeze(1)\n",
    "                valid_preds = model(X_valid)\n",
    "                loss = criterion(valid_preds, y_valid)\n",
    "                end_time = time.time()\n",
    "                # print(f'Validation loop took {end_time - start_time:.3f} seconds')\n",
    "\n",
    "                valid_batch_loss += loss.item()\n",
    "\n",
    "            valid_loss.append(valid_batch_loss / len(validation_loader))\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch + 1}',\n",
    "                  f'Train loss: {train_loss[-1]:.3f}'\n",
    "                  f'Validation loss: {valid_loss[-1]:.3f}')\n",
    "    \n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointNetRegression(30, 1)\n",
    "learning_rate = 0.001\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Model loading took 0.024 seconds\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m, in \u001b[0;36mbest_trainer\u001b[1;34m(model, criterion, optimizer, trainloader, validloader, epochs, patience, verbose)\u001b[0m\n\u001b[0;32m     16\u001b[0m valid_batch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Start the trainer\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader):\n\u001b[0;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIteration \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m, in \u001b[0;36mCalorichEventDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     44\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_with_hit_features\u001b[39m.\u001b[39mrow(idx)\n\u001b[0;32m     45\u001b[0m composite_event_id \u001b[39m=\u001b[39m row[\u001b[39m0\u001b[39m]\n\u001b[0;32m     46\u001b[0m hits \u001b[39m=\u001b[39m (\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhits\n\u001b[0;32m     48\u001b[0m \u001b[39m.\u001b[39;49mfilter(pl\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mcomposite_event_id\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m==\u001b[39;49m composite_event_id)\n\u001b[0;32m     49\u001b[0m \u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mcomposite_event_id\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m---> 50\u001b[0m \u001b[39m.\u001b[39;49mcollect()\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     53\u001b[0m \u001b[39m# Add 3rd dimension as gaussian noise\u001b[39;00m\n\u001b[0;32m     55\u001b[0m noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m30\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\polars\\lazyframe\\frame.py:1501\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, common_subplan_elimination, streaming)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     common_subplan_elimination \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m ldf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf\u001b[39m.\u001b[39moptimization_toggle(\n\u001b[0;32m   1493\u001b[0m     type_coercion,\n\u001b[0;32m   1494\u001b[0m     predicate_pushdown,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     streaming,\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_df(ldf\u001b[39m.\u001b[39;49mcollect())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loss, valid_loss = best_trainer(model, \n",
    "                                 criterion, \n",
    "                                 optimizer, \n",
    "                                 train_loader,\n",
    "                                 validation_loader,\n",
    "                                 epochs=5, \n",
    "                                 patience=5,\n",
    "                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "[INFO] epoch: 1...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     14\u001b[0m     X \u001b[39m=\u001b[39m d[\u001b[39m'\u001b[39m\u001b[39mhits\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device) \u001b[39m# Check why the change into a different datatype and why send it to device\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     y \u001b[39m=\u001b[39m d[\u001b[39m'\u001b[39m\u001b[39mring_radius_cal\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device) \u001b[39m# Remember, I removed the .long() before .to(device) to get the decimal points (does not make sense)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[12], line 50\u001b[0m, in \u001b[0;36mCalorichEventDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     44\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_with_hit_features\u001b[39m.\u001b[39mrow(idx)\n\u001b[0;32m     45\u001b[0m composite_event_id \u001b[39m=\u001b[39m row[\u001b[39m0\u001b[39m]\n\u001b[0;32m     46\u001b[0m hits \u001b[39m=\u001b[39m (\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhits\n\u001b[0;32m     48\u001b[0m \u001b[39m.\u001b[39;49mfilter(pl\u001b[39m.\u001b[39;49mcol(\u001b[39m\"\u001b[39;49m\u001b[39mcomposite_event_id\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m==\u001b[39;49m composite_event_id)\n\u001b[0;32m     49\u001b[0m \u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mcomposite_event_id\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m---> 50\u001b[0m \u001b[39m.\u001b[39;49mcollect()\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     53\u001b[0m \u001b[39m# Add 3rd dimension as gaussian noise\u001b[39;00m\n\u001b[0;32m     55\u001b[0m noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m0.05\u001b[39m, \u001b[39m30\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\merig\\anaconda3\\envs\\591\\lib\\site-packages\\polars\\lazyframe\\frame.py:1501\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, common_subplan_elimination, streaming)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     common_subplan_elimination \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m ldf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf\u001b[39m.\u001b[39moptimization_toggle(\n\u001b[0;32m   1493\u001b[0m     type_coercion,\n\u001b[0;32m   1494\u001b[0m     predicate_pushdown,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1499\u001b[0m     streaming,\n\u001b[0;32m   1500\u001b[0m )\n\u001b[1;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m wrap_df(ldf\u001b[39m.\u001b[39;49mcollect())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "model.to(device)\n",
    "trainTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
    "training_start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    print(\"[INFO] epoch: {}...\".format(epoch + 1))\n",
    "    epoch_start = time.time()\n",
    "    train_losses, train_accs = [], []\n",
    "    samples = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, d in enumerate(train_loader):\n",
    "        X = d['hits'].float().to(device) # Check why the change into a different datatype and why send it to device\n",
    "        y = d['ring_radius_cal'].to(device) # Remember, I removed the .long() before .to(device) to get the decimal points (does not make sense)\n",
    "        predictions = model(X)\n",
    "        loss = criterion(predictions, y) # erased long() from y.long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item() * y.size(0)) # Changed to append\n",
    "        train_accs.append(torch.sub(predictions[0], y).mean().item()) # Added the () in sum()\n",
    "        samples += y.size(0)\n",
    "\n",
    "        print(f\"Epoch: {epoch + 1} step: {i} with loss: {loss.item()} and accuracy: {train_accs[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of d: 2\n",
      "value of i: 0\n",
      "size of X: 16\n",
      "size of y: 16\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(validation_loader, 0):\n",
    "    y = d['ring_radius_cal']\n",
    "    X = d['hits']\n",
    "\n",
    "    print(f\"size of d: {len(d.items())}\" )\n",
    "    print(f\"value of i: {i}\" )\n",
    "    print(f\"size of X: {len(X)}\")\n",
    "    print(f\"size of y: {len(y)}\")\n",
    "\n",
    "\n",
    "    # print(X.size())\n",
    "    # print(y.size())\n",
    "    # print(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of d: 2\n",
      "value of i: 0\n",
      "size of X: 16\n",
      "size of y: 16\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(train_loader, 0):\n",
    "    y = d['ring_radius_cal']\n",
    "    X = d['hits']\n",
    "\n",
    "    print(f\"size of d: {len(d.items())}\" )\n",
    "    print(f\"value of i: {i}\" )\n",
    "    print(f\"size of X: {len(X)}\")\n",
    "    print(f\"size of y: {len(y)}\")\n",
    "\n",
    "\n",
    "    # print(X.size())\n",
    "    # print(y.size())\n",
    "    # print(X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ring_radius_cal': tensor(173.4102),\n",
       " 'hits': tensor([[-3.4970e+02, -2.2774e+02, -4.6963e-02],\n",
       "         [-3.3170e+02, -2.5892e+02,  9.1718e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -6.1191e-02],\n",
       "         [-3.7670e+02, -2.4333e+02, -1.5209e-02],\n",
       "         [-1.4270e+02, -2.5090e+01,  5.6494e-03],\n",
       "         [-3.4970e+02, -2.2774e+02,  3.5191e-02],\n",
       "         [-3.3170e+02, -2.5892e+02,  8.9147e-02],\n",
       "         [-5.2700e+01, -2.4333e+02, -5.1090e-02],\n",
       "         [-7.9700e+01, -2.9009e+02, -3.3477e-03],\n",
       "         [-3.1370e+02, -4.0680e+01,  6.4508e-03],\n",
       "         [-3.1370e+02, -4.0680e+01, -7.5159e-02],\n",
       "         [-1.6700e+01, -1.8097e+02, -3.8311e-02],\n",
       "         [-1.2470e+02,  6.0900e+00,  3.8668e-03],\n",
       "         [-1.6700e+01, -1.1862e+02, -7.5247e-02],\n",
       "         [-9.7700e+01, -2.9009e+02, -1.8152e-03],\n",
       "         [-3.5870e+02, -1.4980e+02,  3.3626e-02],\n",
       "         [-9.7700e+01, -2.9009e+02,  2.6931e-03],\n",
       "         [-1.6700e+01, -1.8097e+02, -3.2215e-02],\n",
       "         [-1.2470e+02,  6.0900e+00, -1.1841e-02],\n",
       "         [-3.4970e+02, -2.2774e+02, -7.3504e-02],\n",
       "         [-3.5870e+02, -1.4980e+02,  3.9915e-02],\n",
       "         [-3.4070e+02, -5.6270e+01, -3.1827e-02],\n",
       "         [-9.7700e+01, -4.0680e+01, -4.4228e-02],\n",
       "         [-6.1700e+01, -4.0680e+01,  6.7874e-02],\n",
       "         [-1.6700e+01, -1.1862e+02, -5.4752e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -7.4192e-03],\n",
       "         [-9.7700e+01, -4.0680e+01,  1.3756e-02],\n",
       "         [-3.5870e+02, -1.4980e+02, -4.1790e-02],\n",
       "         [-1.2470e+02,  6.0900e+00, -3.0841e-04],\n",
       "         [-3.3170e+02, -2.5892e+02,  7.5793e-02]], dtype=torch.float64)}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 0.05, 30)\n",
    "noise = np.expand_dims(noise, 1)\n",
    "noise.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "model = models.resnet50()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "dataset = datasets.FakeData(\n",
    "    size=1000,\n",
    "    transform=transforms.ToTensor())\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for data, target in loader:\n",
    "    data = data.to('cuda', non_blocking=True)\n",
    "    target = target.to('cuda', non_blocking=True)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'d': 6, 'c': 4, 'a': 10, 'b': 8}\n"
     ]
    }
   ],
   "source": [
    "# Python code to merge dict using update() method\n",
    "def Merge(dict1, dict2):\n",
    "\treturn(dict2.update(dict1))\n",
    "\n",
    "\n",
    "# Driver code\n",
    "dict1 = {'a': 10, 'b': 8}\n",
    "dict2 = {'d': 6, 'c': 4}\n",
    "\n",
    "# This returns None\n",
    "print(Merge(dict1, dict2))\n",
    "\n",
    "# changes made in dict2\n",
    "print(dict2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "591",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
